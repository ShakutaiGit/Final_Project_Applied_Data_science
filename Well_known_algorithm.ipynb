{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Well_known_algorithm.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM0TePOIQtwMdVHnJYAPAY7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShakutaiGit/Final_Project_Applied_Data_science/blob/main/Well_known_algorithm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40yCnCufvuBl"
      },
      "source": [
        "relevant imports "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luTxD34ave3s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef385fe2-edd9-4ca0-ab05-fda5a2a13ce4"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.utils import plot_model \n",
        "from tensorflow.python.keras.utils import np_utils\n",
        "from tensorflow.python.keras.models import Sequential, Model\n",
        "from tensorflow.python.keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization\n",
        "from tensorflow.python.keras.layers.convolutional import Conv2D, MaxPooling2D \n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "!pip install optuna\n",
        "import optuna\n",
        "from sklearn.model_selection import KFold\n",
        "from skimage.transform import resize\n",
        "from skimage.transform import rescale\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "import cv2\n",
        "from statistics import mean\n",
        "from google.colab import files\n",
        "import time \n",
        "import csv\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.19.5)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.7/dist-packages (from optuna) (1.6.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.41.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.7/dist-packages (from optuna) (5.0.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.20)\n",
            "Requirement already satisfied: cliff in /usr/local/lib/python3.7/dist-packages (from optuna) (3.8.0)\n",
            "Requirement already satisfied: cmaes>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from optuna) (0.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (20.9)\n",
            "Requirement already satisfied: python-editor>=0.3 in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (1.0.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (2.8.1)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (1.1.4)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.6.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.0)\n",
            "Requirement already satisfied: stevedore>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.3.0)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (5.6.0)\n",
            "Requirement already satisfied: cmd2>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.1.2)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.4.7)\n",
            "Requirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->alembic->optuna) (1.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->sqlalchemy>=1.1.0->optuna) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->sqlalchemy>=1.1.0->optuna) (3.7.4.3)\n",
            "Requirement already satisfied: pyperclip>=1.6 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.2.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: colorama>=0.3.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.4.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OCUqyJev-QR"
      },
      "source": [
        "global variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0rBEpzfwA4x"
      },
      "source": [
        "optimizer = None\n",
        "size = 128 \n",
        "batch_size = 128 # like the original paper \n",
        "classes = 0\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "x_train = []\n",
        "x_test = []\n",
        "y_train = []\n",
        "y_test = []\n",
        "data_shape = None \n",
        "algorithem_name = 'Well_known'\n",
        "database_name = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdFZNHN6v1D-"
      },
      "source": [
        "loading the dataset and pre processing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLsH9p4Kv47W"
      },
      "source": [
        "train_ds ,train_info= tfds.load('oxford_flowers102', split='test[:90%]', with_info=True)\n",
        "# val_ds,val_info = tfds.load('oxford_flowers102', split='train[80%:90%]', with_info=True)\n",
        "test_ds , test_info = tfds.load('oxford_flowers102', split='test[90%:]', with_info=True)\n",
        "## pre processing \n",
        "database_name = train_info.name\n",
        "resize_and_rescale = tf.keras.Sequential([\n",
        "layers.experimental.preprocessing.Resizing(size, size),\n",
        "layers.experimental.preprocessing.Rescaling(1./255)\n",
        "])\n",
        "\n",
        "def pre_process(data):\n",
        "  pictures=[]\n",
        "  labels = []\n",
        "  for i in data:\n",
        "    temp = resize_and_rescale(i['image'])\n",
        "    temp = np.asarray(temp)\n",
        "    pictures.append(temp)\n",
        "    labels.append(int(i['label']))\n",
        "  return np.asarray(pictures),np.asarray(labels)\n",
        "\n",
        "x_train,y_train =pre_process(train_ds)\n",
        "data_shape= x_train[0].shape\n",
        "x_test,y_test =pre_process(test_ds)\n",
        "classes = train_info.features['label'].num_classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpE2w6Liv8tt"
      },
      "source": [
        "def creating_the_model():\n",
        "  inputs = layers.Input(shape=data_shape)\n",
        "  pre_trained_model = keras.applications.ResNet50V2(include_top=False, weights='imagenet',input_tensor=inputs,pooling='avg')\n",
        "  pre_trained_model.trainable= False\n",
        "  \n",
        "  x = layers.BatchNormalization()(pre_trained_model.output)\n",
        "  top_dropout_rate = 0.5\n",
        "  x = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
        "  outputs = layers.Dense(classes, activation=\"softmax\", name=\"pred\")(x)\n",
        "  model = tf.keras.Model(inputs, outputs, name=\"ResNet\")\n",
        "  #unfreeze some layers of the pretrained model\n",
        "  for layer in model.layers[-10:]:\n",
        "    if not isinstance(layer, layers.BatchNormalization):\n",
        "        layer.trainable = True\n",
        "  return model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FiaPOxPdUIE"
      },
      "source": [
        "def objective(trial,outer_x_train,outer_y_train):\n",
        "\n",
        "\n",
        "  internal_kfold = KFold(n_splits=3, shuffle=True)\n",
        "  fold_acc = []  \n",
        "  for inner_train_index,inner_test_index in internal_kfold.split(outer_x_train,outer_y_train):\n",
        "    inner_x_train, inner_x_test = outer_x_train[inner_train_index], outer_x_train[inner_test_index]\n",
        "    inner_y_train, inner_y_test = outer_y_train[inner_train_index], outer_y_train[inner_test_index]\n",
        "    model = creating_the_model()\n",
        "    model.compile(\n",
        "    loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(\n",
        "  learning_rate=trial.suggest_float(name=\"lr\", low = 0.00001,high= 0.5, log=True),\n",
        "  beta_1=trial.suggest_float(name=\"beta_1\", low = 0,high=1), \n",
        "  beta_2=trial.suggest_float(name=\"beta_2\", low = 0,high=1)\n",
        "      ), metrics=[\"accuracy\"]\n",
        "  )\n",
        "    model.fit(\n",
        "        x=inner_x_train,\n",
        "        y=to_categorical(inner_y_train,num_classes=classes),\n",
        "        # validation_data= (inner_x_test,to_categorical(,inner_y_test)),\n",
        "        # shuffle=True,\n",
        "        validation_split=0.1,\n",
        "        batch_size=batch_size,\n",
        "        epochs=5\n",
        "    )\n",
        "    score = model.evaluate(inner_x_test,to_categorical(inner_y_test, num_classes=classes) , verbose=0)\n",
        "    fold_acc.append(score[1] * 100)\n",
        "  return mean(fold_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0q4hZH1l3SOL"
      },
      "source": [
        "def fold_dict_creator(Hyper_Parameters_Values,score,training_time,inference_time,fold):\n",
        "  fold_dict = {}\n",
        "  fold_dict['Dataset Name'] = database_name\n",
        "  fold_dict['Algorithm Name'] = algorithem_name\n",
        "  fold_dict['Cross Validation [1-10]'] = fold\n",
        "  fold_dict['Hyper-Parameters Values'] = Hyper_Parameters_Values\n",
        "  fold_dict['Accuracy'] = score[1]\n",
        "  fold_dict['TPR'] = score[2]\n",
        "  fold_dict['FPR'] = score[3]\n",
        "  fold_dict['Precision'] = score[4]\n",
        "  fold_dict['AUC'] = score[5]\n",
        "  fold_dict['PR-Curve'] = score[6]\n",
        "  fold_dict['Training Time'] = training_time\n",
        "  fold_dict['Inference Time'] = inference_time\n",
        "  return fold_dict\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhxOlNiUc4Ki"
      },
      "source": [
        "outer_kfold = KFold(n_splits=10, shuffle=True)\n",
        "fold_num = 0\n",
        "dict_data= []\n",
        "for outer_train_index,outer_test_index in outer_kfold.split(x_train, y_train):\n",
        "  fold_num += 1\n",
        "  outer_x_train, outer_x_test = x_train[outer_train_index], x_train[outer_test_index]\n",
        "  outer_y_train, outer_y_test = y_train[outer_train_index], y_train[outer_test_index]\n",
        "  study = optuna.create_study(direction=\"maximize\")\n",
        "  study.optimize(lambda trail:objective(trail,outer_x_train,outer_y_train), n_trials=50)\n",
        "  model = creating_the_model()\n",
        "  model.compile(\n",
        "    loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(\n",
        "  learning_rate=study.best_params[\"lr\"],\n",
        "  beta_1=study.best_params[\"beta_1\"], \n",
        " beta_2=study.best_params[\"beta_2\"])\n",
        "      , metrics=[\"accuracy\", tf.keras.metrics.SensitivityAtSpecificity(0.5),\n",
        "      tf.keras.metrics.SpecificityAtSensitivity(0.5), \n",
        "      tf.keras.metrics.Precision(),\n",
        "      tf.keras.metrics.AUC(),\n",
        "      tf.keras.metrics.AUC(curve = 'pr')]\n",
        "  )\n",
        "  start_time = time.time()\n",
        "  model_info = model.fit(\n",
        "    outer_x_train,\n",
        "    to_categorical(outer_y_train,num_classes=classes),\n",
        "    validation_split= 0.15,\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size,\n",
        "    epochs=5,\n",
        "  )\n",
        "  training_time = time.time() - start_time\n",
        "  start_time = time.time()\n",
        "  score = model.evaluate(outer_x_test,to_categorical(outer_y_test,num_classes=classes))\n",
        "  print(model.metrics_names)\n",
        "  inference_time = time.time() - start_time\n",
        "  dict_data.append(fold_dict_creator(str(study.best_params), score, training_time , inference_time, fold_num))\n",
        "csv_file = \"results_algo_{}_data_set{}.csv\".format(algorithem_name,database_name)\n",
        "with open(csv_file, 'w') as csvfile:\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=dict_data[0].keys())\n",
        "    writer.writeheader()\n",
        "    for data in dict_data:\n",
        "        writer.writerow(data)\n",
        "files.download(csv_file)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "JvHgSKtOvAoM",
        "outputId": "a31a8feb-2e9a-4d27-a2ea-7a4fd2626b78"
      },
      "source": [
        "import csv\n",
        "csv_file = \"results_algo_{}_data_set{}.csv\".format(algorithem_name,database_name)\n",
        "with open(csv_file, 'w') as csvfile:\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=dict_data[0].keys())\n",
        "    writer.writeheader()\n",
        "    for data in dict_data:\n",
        "        writer.writerow(data)\n",
        "files.download(csv_file)  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_e990f3c3-ca03-463b-90b0-9e144461e691\", \"results_algo_Well_known_data_setbeans.csv\", 2774)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}